version: "3.8"

services:
  anki:
    image: ghcr.io/mlcivilengineer/anki-desktop-docker:latest
    container_name: ankai-anki
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=UTC
    volumes:
      - anki_data:/config
      - ./anki/addons21:/config/.local/share/Anki2/addons21
    ports:
      - "3000:3000"   # VNC web interface (remove from firewall after setup)
    expose:
      - "8765"        # AnkiConnect API (internal only)
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8765"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  backend:
    build: ./backend
    container_name: ankai-backend
    environment:
      - ANKI_CONNECT_URL=http://anki:8765
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_MODEL=${GROQ_MODEL:-llama-3.3-70b-versatile}
      - LLM_PROVIDER=${LLM_PROVIDER:-groq}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-}
    expose:
      - "8000"
    depends_on:
      anki:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build: ./frontend
    container_name: ankai-frontend
    expose:
      - "80"
    depends_on:
      - backend
    restart: unless-stopped

  caddy:
    image: caddy:2-alpine
    container_name: ankai-caddy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

volumes:
  anki_data:
  caddy_data:
  caddy_config:
